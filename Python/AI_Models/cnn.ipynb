{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f708ac1",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio. Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced—in some cases—by newer deep learning architectures such as the transformer.\n",
    "Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections. For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 × 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a21617",
   "metadata": {},
   "source": [
    "## Simple Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ecd7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d057f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake \"Image\": 1 channel, 4x4 pixels, 2D array\n",
    "\n",
    "image = np.array([\n",
    "    [1, 2, 0, 1],\n",
    "    [0, 1, 3, 1],\n",
    "    [2, 2, 1, 0],\n",
    "    [1, 0, 1, 3]\n",
    "])\n",
    "\n",
    "# Simple 2x2 filter (kernel)\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20f85ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution without padding or stride\n",
    "\n",
    "def convolve2d(image, kernel):\n",
    "    # Get dimensions of image and kernel\n",
    "    h, w = image.shape\n",
    "    kh, kw = kernel.shape\n",
    "    # Calculate output dimensions\n",
    "    output = np.zeros((h - kh + 1, w - kw + 1))\n",
    "\n",
    "    # Perform convolution\n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            # Extract the region of interest from the image\n",
    "            region = image[i:i + kh, j:j + kw]\n",
    "            # Perform element-wise multiplication and sum the result\n",
    "            output[i, j] = np.sum(region * kernel)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaa8464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ReLU activation function\n",
    "# ReLU: Rectified Linear Unit\n",
    "# It replaces negative values with zero and keeps positive values unchanged\n",
    "# This is a common activation function in neural networks\n",
    "# It helps to introduce non-linearity in the model\n",
    "# and allows the model to learn complex patterns\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c254419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply max pooling\n",
    "# Max pooling is a down-sampling technique used in convolutional neural networks\n",
    "# It reduces the spatial dimensions of the input while retaining important features\n",
    "# It takes the maximum value from a defined window (e.g., 2x2) and moves it across the input\n",
    "# This helps to reduce the number of parameters and computations in the network\n",
    "# It also helps to make the model more robust to small translations in the input\n",
    "\n",
    "def max_pooling(feature_map):\n",
    "    # Get dimensions of the feature map\n",
    "    h, w = feature_map.shape\n",
    "    pooled_h = h // 2\n",
    "    pooled_w = w // 2\n",
    "    pooled = np.zeros((pooled_h, pooled_w))\n",
    "    # Perform max pooling\n",
    "    for i in range(pooled_h):\n",
    "        for j in range(pooled_w):\n",
    "            # Extract the region of interest from the feature map\n",
    "            region = feature_map[i * 2:i * 2 + 2, j * 2:j * 2 + 2]      # 2x2 pooling window\n",
    "            # Take the maximum value from the region                       \n",
    "            pooled[i, j] = np.max(region)\n",
    "            \n",
    "    return pooled\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dea829d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through steps\n",
    "conv_out = convolve2d(image, kernel)\n",
    "relu_out = relu(conv_out)\n",
    "pooled_out = max_pooling(relu_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cd7a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution Output:\n",
      " [[2. 5. 1.]\n",
      " [2. 2. 3.]\n",
      " [2. 3. 4.]]\n",
      "After ReLU:\n",
      " [[2. 5. 1.]\n",
      " [2. 2. 3.]\n",
      " [2. 3. 4.]]\n",
      "After Max Pooling:\n",
      " [[5.]]\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "\n",
    "# Ensure all required variables are defined\n",
    "print(\"Convolution Output:\\n\", conv_out)    # Convolution result\n",
    "print(\"After ReLU:\\n\", relu_out)            # After ReLU activation \n",
    "print(\"After Max Pooling:\\n\", pooled_out)   # After max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a7ffe",
   "metadata": {},
   "source": [
    "## PyTorch Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34bb705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f498dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform images to tensor and normalize to [0, 1] range\n",
    "\n",
    "trnasform = transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2a6df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Download and load MNIST dataset\n",
    "# MNIST is a dataset of handwritten digits (0-9) commonly used for image classification tasks\n",
    "# It contains 60,000 training images and 10,000 test images\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=trnasform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f65d5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Definition\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size = 3)    # 1 input channel, 8 output channels, 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)                   # 2x2 max pooling with stride 2\n",
    "        self.fc1 = nn.Linear(8 * 13 * 13, 10)            # Fully connected layer (input size: 8*13*13, output size: 10 classes)\n",
    "\n",
    "        # The output of the convolution, ReLU activation, and max pooling steps are printed.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Convolution + ReLU + Max Pooling\n",
    "        x = x.view(-1, 8 * 13 * 13)               # Flatten the tensor \n",
    "        x = self.fc1(x)                           # Fully connected layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "969998ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)  # Adam optimizer with learning rate of 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36d41123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits for 64 images: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    outputs = model(images)  # Forward pass through the model\n",
    "    loss = criterion(outputs, labels)  # Calculate loss\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    loss.backward()  # Backward pass to calculate gradients\n",
    "    optimizer.step()  # Update model parameters using optimizer\n",
    "    break   # Break after one batch for demonstration purposes\n",
    "\n",
    "print(\"Output logits for 64 images:\", outputs.shape)  # Output shape after forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f7817",
   "metadata": {},
   "source": [
    "## PyTorch With GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5738cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61b4c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform images to tensor and normalize to [0, 1] range\n",
    "\n",
    "trnasform = transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6fa62fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load MNIST dataset\n",
    "# MNIST is a dataset of handwritten digits (0-9) commonly used for image classification tasks\n",
    "# It contains 60,000 training images and 10,000 test images\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=trnasform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a1e9c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU Device Check\n",
    "# Check if GPU is available and set device accordingly\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)  # Print the device being used (CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76f09615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Definition\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size = 3)    # 1 input channel, 8 output channels, 3x3 kernel\n",
    "        self.pool = nn.MaxPool2d(2, 2)                   # 2x2 max pooling with stride 2\n",
    "        self.fc1 = nn.Linear(8 * 13 * 13, 10)            # Fully connected layer (input size: 8*13*13, output size: 10 classes)\n",
    "\n",
    "        # The output of the convolution, ReLU activation, and max pooling steps are printed.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Convolution + ReLU + Max Pooling\n",
    "        x = x.view(-1, 8 * 13 * 13)               # Flatten the tensor \n",
    "        x = self.fc1(x)                           # Fully connected layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "897a4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "\n",
    "model = SimpleCNN().to(device)  # Move model to GPU if available\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)  # Adam optimizer with learning rate of 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "297a2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits for 64 images: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    images, labels = images.to(device), labels.to(device)  # Move data to GPU if available\n",
    "    outputs = model(images)  # Forward pass through the model\n",
    "    loss = criterion(outputs, labels)  # Calculate loss\n",
    "    \n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    loss.backward()  # Backward pass to calculate gradients\n",
    "    optimizer.step()  # Update model parameters using optimizer\n",
    "    break   # Break after one batch for demonstration purposes\n",
    "\n",
    "print(\"Output logits for 64 images:\", outputs.shape)  # Output shape after forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9440ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
