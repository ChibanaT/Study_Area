{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f13a45fe",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "Recurrent neural networks (RNNs) are a class of artificial neural networks designed for processing sequential data, such as text, speech, and time series, where the order of elements is important. Unlike feedforward neural networks, which process inputs independently, RNNs utilize recurrent connections, where the output of a neuron at one time step is fed back as input to the network at the next time step. This enables RNNs to capture temporal dependencies and patterns within sequences.\n",
    "The fundamental building block of RNNs is the recurrent unit, which maintains a hidden stateâ€”a form of memory that is updated at each time step based on the current input and the previous hidden state. This feedback mechanism allows the network to learn from past inputs and incorporate that knowledge into its current processing. RNNs have been successfully applied to tasks such as unsegmented, connected handwriting recognition, speech recognition, natural language processing, and neural machine translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c250b31",
   "metadata": {},
   "source": [
    "## Simple Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad0f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a31a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary and one-hot encoding\n",
    "\n",
    "chars = \"helo\"\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbcb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output sequences\n",
    "\n",
    "sequence = \"hello\"\n",
    "X_seq = [char_to_idx[ch] for ch in sequence[:-1]] # Input sequence \"hell\"\n",
    "Y_seq = [char_to_idx[ch] for ch in sequence[1:]] # Output sequence \"ello\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad893d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding input and output sequences\n",
    "\n",
    "def one_hot(i, vocab_size):\n",
    "    \"\"\"One-hot encode an integer index.\"\"\"\n",
    "    vec = np.zeros((vocab_size,))\n",
    "    vec[i] = 1\n",
    "    return vec\n",
    "\n",
    "X = np.array([one_hot(i, len(chars)) for i in X_seq]) # One-hot encoded input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa41025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN parameters\n",
    "\n",
    "hidden_size = 4 # Number of hidden units\n",
    "input_size = len(chars) # Size of input layer (vocabulary size)\n",
    "output_size = len(chars) # Size of output layer (vocabulary size)\n",
    "\n",
    "Wxh = np.random.randn(hidden_size, input_size) * 0.01 # Input to hidden weights\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01 # Hidden to hidden weights\n",
    "Why = np.random.randn(output_size, hidden_size) * 0.01 # Hidden to output weights\n",
    "bh = np.zeros((hidden_size,)) # Hidden bias\n",
    "by = np.zeros((output_size,)) # Output bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47efed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through the RNN\n",
    "\n",
    "h = np.zeros((hidden_size,)) # Initial hidden state\n",
    "outputs = [] # Store outputs for each time step\n",
    "\n",
    "for x_t in X:\n",
    "    h = np.tanh(Wxh @ x_t + Whh @ h + bh) # Update hidden state\n",
    "    y = Why @ h + by # Compute output\n",
    "    outputs.append(y) # Store output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fec249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 prediction: [0.25 0.25 0.25 0.25]\n",
      "Step 1 prediction: [0.25 0.25 0.25 0.25]\n",
      "Step 2 prediction: [0.25 0.25 0.25 0.25]\n",
      "Step 3 prediction: [0.25 0.25 0.25 0.25]\n"
     ]
    }
   ],
   "source": [
    "# Print softmax probabilities\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x)) # Subtract max for numerical stability\n",
    "    return exps / np.sum(exps)\n",
    "\n",
    "for i, y in enumerate(outputs):\n",
    "    p = softmax(y) # Compute softmax probabilities\n",
    "    print(f\"Step {i} prediction:\", p.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd589947",
   "metadata": {},
   "source": [
    "# PyTorch Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc05346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28633492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "chars = \"helo\"\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
    "sequence = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efea6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode input and output sequence\n",
    "\n",
    "input_seq = [char_to_idx[ch] for ch in sequence[:-1]] # Input sequence \"hell\"\n",
    "target_seq = [char_to_idx[ch] for ch in sequence[1:]] # Output sequence \"ello\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1fc2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to PyTorch tensors\n",
    "\n",
    "input_tensor = torch.eye(len(chars))[input_seq].unsqueeze(1) # Shape: (seq_len, batch_size, input_size)\n",
    "target_tensor = torch.tensor(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e2a2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN model\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        out, h = self.rnn(x, h)\n",
    "        out = self.fc(out.squeeze(1)) # Remove batch dimension\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a182bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model, loss function, and optimizer\n",
    "\n",
    "model = CharRNN(input_size = 4, hidden_size = 8, output_size = 4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a226087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits:\n",
      " tensor([[-0.0728, -0.2635, -0.1429,  0.0543],\n",
      "        [ 0.1242, -0.3715, -0.1328,  0.1894],\n",
      "        [-0.1763, -0.3454, -0.1156,  0.1728],\n",
      "        [-0.1083, -0.4030, -0.2436,  0.1000]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Train one step\n",
    "\n",
    "output, _ = model(input_tensor) # Forward pass\n",
    "loss = criterion(output, target_tensor) # Compute loss\n",
    "loss.backward() # Backpropagation\n",
    "optimizer.step() # Update weights\n",
    "\n",
    "print(\"Output logits:\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5494ff",
   "metadata": {},
   "source": [
    "## PyTorch With GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "193e68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24e4397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "chars = \"helo\"\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
    "sequence = \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "373aacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode input and output sequence\n",
    "\n",
    "input_seq = [char_to_idx[ch] for ch in sequence[:-1]] # Input sequence \"hell\"\n",
    "target_seq = [char_to_idx[ch] for ch in sequence[1:]] # Output sequence \"ello\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f190c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to PyTorch tensors\n",
    "\n",
    "input_tensor = torch.eye(len(chars))[input_seq].unsqueeze(1) # Shape: (seq_len, batch_size, input_size)\n",
    "target_tensor = torch.tensor(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96347b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN model\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        out, h = self.rnn(x, h)\n",
    "        out = self.fc(out.squeeze(1)) # Remove batch dimension\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0da01e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Check for GPU\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56fae9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model, loss function, and optimizer\n",
    "\n",
    "model = CharRNN(input_size = 4, hidden_size = 8, output_size = 4).to(device) # Move model to GPU if available\n",
    "input_tensor = input_tensor.to(device) # Move input tensor to GPU if available\n",
    "target_tensor = target_tensor.to(device) # Move target tensor to GPU if available\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52596f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output predictions:\n",
      " [[0.15 0.23 0.37 0.26]\n",
      " [0.13 0.19 0.45 0.23]\n",
      " [0.14 0.23 0.38 0.26]\n",
      " [0.13 0.19 0.37 0.31]]\n"
     ]
    }
   ],
   "source": [
    "# Train one step\n",
    "\n",
    "output, _ = model(input_tensor) # Forward pass\n",
    "loss = criterion(output, target_tensor) # Compute loss\n",
    "loss.backward() # Backpropagation\n",
    "optimizer.step() # Update weights\n",
    "\n",
    "print(\"Output predictions:\\n\", torch.softmax(output, dim=1).cpu().detach().numpy().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aaa5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
